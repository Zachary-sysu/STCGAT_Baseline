ssh://root@10.107.41.171:22/root/anaconda3/envs/ztorch/bin/python -u /home/ZSQProject/test_ncde/model/Run_cde.py
/home/ZSQProject/test_ncde
Namespace(batch_size=64, cheb_k=2, column_wise=False, comment='', cuda=True, dataset='PEMSD4', debug=False, default_graph=True, device=2, early_stop=True, early_stop_patience=15, embed_dim=10, epochs=100, g_type='agc', grad_norm=False, hid_dim=128, hid_hid_dim=128, horizon=12, input_dim=2, lag=12, log_dir='../runs', log_step=20, loss_func='mae', lr_decay=False, lr_decay_rate=0.3, lr_decay_step='5,20,40,70', lr_init=0.001, mae_thresh=None, mape_thresh=0.0, max_grad_norm=5, missing_rate=0.1, missing_test=False, mode='train', model='GCDE', model_path='', model_type='type1', normalizer='std', num_layers=3, num_nodes=307, output_dim=1, plot=False, real_value=True, seed=10, solver='rk4', teacher_forcing=False, tensorboard=False, test_ratio=0.2, tod=False, val_ratio=0.2, weight_decay=0.001)
NeuralGCDE(
  (func_f): FinalTanh_f(
    input_channels: 2, hidden_channels: 128, hidden_hidden_channels: 128, num_hidden_layers: 3
    (linear_in): Linear(in_features=128, out_features=128, bias=True)
    (linears): ModuleList(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Linear(in_features=128, out_features=128, bias=True)
    )
    (linear_out): Linear(in_features=128, out_features=256, bias=True)
  )
  (func_g): VectorField_g(
    input_channels: 2, hidden_channels: 128, hidden_hidden_channels: 128, num_hidden_layers: 3
    (linear_in): Linear(in_features=128, out_features=128, bias=True)
    (linear_out): Linear(in_features=128, out_features=16384, bias=True)
  )
  (end_conv): Conv2d(1, 12, kernel_size=(1, 128), stride=(1, 1))
  (initial_h): Linear(in_features=2, out_features=128, bias=True)
  (initial_z): Linear(in_features=2, out_features=128, bias=True)
)
*****************Model Parameter*****************
node_embeddings torch.Size([307, 10]) True
func_f.linear_in.weight torch.Size([128, 128]) True
func_f.linear_in.bias torch.Size([128]) True
func_f.linears.0.weight torch.Size([128, 128]) True
func_f.linears.0.bias torch.Size([128]) True
func_f.linears.1.weight torch.Size([128, 128]) True
func_f.linears.1.bias torch.Size([128]) True
func_f.linear_out.weight torch.Size([256, 128]) True
func_f.linear_out.bias torch.Size([256]) True
func_g.node_embeddings torch.Size([307, 10]) True
func_g.weights_pool torch.Size([10, 2, 128, 128]) True
func_g.bias_pool torch.Size([10, 128]) True
func_g.linear_in.weight torch.Size([128, 128]) True
func_g.linear_in.bias torch.Size([128]) True
func_g.linear_out.weight torch.Size([16384, 128]) True
func_g.linear_out.bias torch.Size([16384]) True
end_conv.weight torch.Size([12, 1, 1, 128]) True
end_conv.bias torch.Size([12]) True
initial_h.weight torch.Size([128, 2]) True
initial_h.bias torch.Size([128]) True
initial_z.weight torch.Size([128, 2]) True
initial_z.bias torch.Size([128]) True
Total params num: 2550024
*****************Finish Parameter****************
mean.shape: (1, 1, 3, 1)
std.shape: (1, 1, 3, 1)
mean: (1, 1, 1, 1)
std: (1, 1, 1, 1)
Train:  (10181, 12, 307, 1) (10181, 12, 307, 1)
Val:  (3394, 12, 307, 1) (3394, 12, 307, 1)
Test:  (3394, 12, 307, 1) (3394, 12, 307, 1)
Creat Log File in:  ../runs/PEMSD4/07-12-10h39m_PEMSD4_GCDE_type1_embed{10}hid{128}hidhid{128}lyrs{3}lr{0.001}wd{0.001}/run.log
2022-07-12 10:39: Experiment log path in: ../runs/PEMSD4/07-12-10h39m_PEMSD4_GCDE_type1_embed{10}hid{128}hidhid{128}lyrs{3}lr{0.001}wd{0.001}
*****************Model Parameter*****************
node_embeddings torch.Size([307, 10]) True
func_f.linear_in.weight torch.Size([128, 128]) True
func_f.linear_in.bias torch.Size([128]) True
func_f.linears.0.weight torch.Size([128, 128]) True
func_f.linears.0.bias torch.Size([128]) True
func_f.linears.1.weight torch.Size([128, 128]) True
func_f.linears.1.bias torch.Size([128]) True
func_f.linear_out.weight torch.Size([256, 128]) True
func_f.linear_out.bias torch.Size([256]) True
func_g.node_embeddings torch.Size([307, 10]) True
func_g.weights_pool torch.Size([10, 2, 128, 128]) True
func_g.bias_pool torch.Size([10, 128]) True
func_g.linear_in.weight torch.Size([128, 128]) True
func_g.linear_in.bias torch.Size([128]) True
func_g.linear_out.weight torch.Size([16384, 128]) True
func_g.linear_out.bias torch.Size([16384]) True
end_conv.weight torch.Size([12, 1, 1, 128]) True
end_conv.bias torch.Size([12]) True
initial_h.weight torch.Size([128, 2]) True
initial_h.bias torch.Size([128]) True
initial_z.weight torch.Size([128, 2]) True
initial_z.bias torch.Size([128]) True
Total params num: 2550024
*****************Finish Parameter****************
2022-07-12 10:39: Argument batch_size: 64
2022-07-12 10:39: Argument cheb_k: 2
2022-07-12 10:39: Argument column_wise: False
2022-07-12 10:39: Argument comment: ''
2022-07-12 10:39: Argument cuda: True
2022-07-12 10:39: Argument dataset: 'PEMSD4'
2022-07-12 10:39: Argument debug: False
2022-07-12 10:39: Argument default_graph: True
2022-07-12 10:39: Argument device: 2
2022-07-12 10:39: Argument early_stop: True
2022-07-12 10:39: Argument early_stop_patience: 15
2022-07-12 10:39: Argument embed_dim: 10
2022-07-12 10:39: Argument epochs: 100
2022-07-12 10:39: Argument g_type: 'agc'
2022-07-12 10:39: Argument grad_norm: False
2022-07-12 10:39: Argument hid_dim: 128
2022-07-12 10:39: Argument hid_hid_dim: 128
2022-07-12 10:39: Argument horizon: 12
2022-07-12 10:39: Argument input_dim: 2
2022-07-12 10:39: Argument lag: 12
2022-07-12 10:39: Argument log_dir: '../runs/PEMSD4/07-12-10h39m_PEMSD4_GCDE_type1_embed{10}hid{128}hidhid{128}lyrs{3}lr{0.001}wd{0.001}'
2022-07-12 10:39: Argument log_step: 20
2022-07-12 10:39: Argument loss_func: 'mae'
2022-07-12 10:39: Argument lr_decay: False
2022-07-12 10:39: Argument lr_decay_rate: 0.3
2022-07-12 10:39: Argument lr_decay_step: '5,20,40,70'
2022-07-12 10:39: Argument lr_init: 0.001
2022-07-12 10:39: Argument mae_thresh: None
2022-07-12 10:39: Argument mape_thresh: 0.0
2022-07-12 10:39: Argument max_grad_norm: 5
2022-07-12 10:39: Argument missing_rate: 0.1
2022-07-12 10:39: Argument missing_test: False
2022-07-12 10:39: Argument mode: 'train'
2022-07-12 10:39: Argument model: 'GCDE'
2022-07-12 10:39: Argument model_path: ''
2022-07-12 10:39: Argument model_type: 'type1'
2022-07-12 10:39: Argument normalizer: 'std'
2022-07-12 10:39: Argument num_layers: 3
2022-07-12 10:39: Argument num_nodes: 307
2022-07-12 10:39: Argument output_dim: 1
2022-07-12 10:39: Argument plot: False
2022-07-12 10:39: Argument real_value: True
2022-07-12 10:39: Argument seed: 10
2022-07-12 10:39: Argument solver: 'rk4'
2022-07-12 10:39: Argument teacher_forcing: False
2022-07-12 10:39: Argument tensorboard: False
2022-07-12 10:39: Argument test_ratio: 0.2
2022-07-12 10:39: Argument tod: False
2022-07-12 10:39: Argument val_ratio: 0.2
2022-07-12 10:39: Argument weight_decay: 0.001
2022-07-12 10:39: NeuralGCDE(
  (func_f): FinalTanh_f(
    input_channels: 2, hidden_channels: 128, hidden_hidden_channels: 128, num_hidden_layers: 3
    (linear_in): Linear(in_features=128, out_features=128, bias=True)
    (linears): ModuleList(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): Linear(in_features=128, out_features=128, bias=True)
    )
    (linear_out): Linear(in_features=128, out_features=256, bias=True)
  )
  (func_g): VectorField_g(
    input_channels: 2, hidden_channels: 128, hidden_hidden_channels: 128, num_hidden_layers: 3
    (linear_in): Linear(in_features=128, out_features=128, bias=True)
    (linear_out): Linear(in_features=128, out_features=16384, bias=True)
  )
  (end_conv): Conv2d(1, 12, kernel_size=(1, 128), stride=(1, 1))
  (initial_h): Linear(in_features=2, out_features=128, bias=True)
  (initial_z): Linear(in_features=2, out_features=128, bias=True)
)
2022-07-12 10:39: Total params: 2550024
2022-07-12 10:39: Train Epoch 1: 0/159 Loss: 194.294281
2022-07-12 10:41: Train Epoch 1: 20/159 Loss: 100.407051
2022-07-12 10:42: Train Epoch 1: 40/159 Loss: 40.895195
2022-07-12 10:44: Train Epoch 1: 60/159 Loss: 33.524521
2022-07-12 10:46: Train Epoch 1: 80/159 Loss: 40.131573
2022-07-12 10:47: Train Epoch 1: 100/159 Loss: 31.688198
2022-07-12 10:49: Train Epoch 1: 120/159 Loss: 35.244297
2022-07-12 10:50: Train Epoch 1: 140/159 Loss: 38.626251
2022-07-12 10:52: **********Train Epoch 1: averaged Loss: 49.025916
2022-07-12 10:53: **********Val Epoch 1: average Loss: 30.804197
2022-07-12 10:53: *********************************Current best model saved!
2022-07-12 10:53: Train Epoch 2: 0/159 Loss: 30.617346
2022-07-12 10:55: Train Epoch 2: 20/159 Loss: 37.172138
2022-07-12 10:56: Train Epoch 2: 40/159 Loss: 27.276569
2022-07-12 10:58: Train Epoch 2: 60/159 Loss: 26.247766
2022-07-12 10:59: Train Epoch 2: 80/159 Loss: 28.908939
2022-07-12 11:01: Train Epoch 2: 100/159 Loss: 28.511665
2022-07-12 11:02: Train Epoch 2: 120/159 Loss: 27.619627
2022-07-12 11:04: Train Epoch 2: 140/159 Loss: 26.664516
2022-07-12 11:05: **********Train Epoch 2: averaged Loss: 28.705817
2022-07-12 11:07: **********Val Epoch 2: average Loss: 26.736096
2022-07-12 11:07: *********************************Current best model saved!
2022-07-12 11:07: Train Epoch 3: 0/159 Loss: 28.565491
2022-07-12 11:08: Train Epoch 3: 20/159 Loss: 27.448534
2022-07-12 11:10: Train Epoch 3: 40/159 Loss: 24.720964
2022-07-12 11:11: Train Epoch 3: 60/159 Loss: 22.656994
2022-07-12 11:13: Train Epoch 3: 80/159 Loss: 28.192522
2022-07-12 11:14: Train Epoch 3: 100/159 Loss: 24.950317
2022-07-12 11:16: Train Epoch 3: 120/159 Loss: 24.848703
2022-07-12 11:18: Train Epoch 3: 140/159 Loss: 22.887831
2022-07-12 11:19: **********Train Epoch 3: averaged Loss: 25.579555
2022-07-12 11:20: **********Val Epoch 3: average Loss: 25.190904
2022-07-12 11:20: *********************************Current best model saved!
2022-07-12 11:20: Train Epoch 4: 0/159 Loss: 23.056330
2022-07-12 11:22: Train Epoch 4: 20/159 Loss: 25.271563
2022-07-12 11:23: Train Epoch 4: 40/159 Loss: 21.363991
2022-07-12 11:25: Train Epoch 4: 60/159 Loss: 24.465189
2022-07-12 11:27: Train Epoch 4: 80/159 Loss: 23.073799
2022-07-12 11:28: Train Epoch 4: 100/159 Loss: 23.764107
2022-07-12 11:30: Train Epoch 4: 120/159 Loss: 25.676867
2022-07-12 11:31: Train Epoch 4: 140/159 Loss: 23.785894
2022-07-12 11:33: **********Train Epoch 4: averaged Loss: 23.665897
2022-07-12 11:34: **********Val Epoch 4: average Loss: 24.119340
2022-07-12 11:34: *********************************Current best model saved!
2022-07-12 11:34: Train Epoch 5: 0/159 Loss: 21.655771
2022-07-12 11:36: Train Epoch 5: 20/159 Loss: 22.399509
2022-07-12 11:37: Train Epoch 5: 40/159 Loss: 22.790142
2022-07-12 11:39: Train Epoch 5: 60/159 Loss: 24.312166
2022-07-12 11:40: Train Epoch 5: 80/159 Loss: 21.882818
2022-07-12 11:42: Train Epoch 5: 100/159 Loss: 23.210388
2022-07-12 11:43: Train Epoch 5: 120/159 Loss: 21.598824
2022-07-12 11:45: Train Epoch 5: 140/159 Loss: 24.085510
2022-07-12 11:46: **********Train Epoch 5: averaged Loss: 22.492347
2022-07-12 11:48: **********Val Epoch 5: average Loss: 22.703218
2022-07-12 11:48: *********************************Current best model saved!
2022-07-12 11:48: Train Epoch 6: 0/159 Loss: 20.709936
2022-07-12 11:49: Train Epoch 6: 20/159 Loss: 21.821505
2022-07-12 11:51: Train Epoch 6: 40/159 Loss: 23.387049
2022-07-12 11:52: Train Epoch 6: 60/159 Loss: 22.283829
2022-07-12 11:54: Train Epoch 6: 80/159 Loss: 23.115112
2022-07-12 11:55: Train Epoch 6: 100/159 Loss: 24.580128
2022-07-12 11:57: Train Epoch 6: 120/159 Loss: 22.128445
2022-07-12 11:59: Train Epoch 6: 140/159 Loss: 23.285475
2022-07-12 12:00: **********Train Epoch 6: averaged Loss: 21.893682
2022-07-12 12:01: **********Val Epoch 6: average Loss: 23.856748
2022-07-12 12:01: Train Epoch 7: 0/159 Loss: 21.904634
2022-07-12 12:03: Train Epoch 7: 20/159 Loss: 21.538385
2022-07-12 12:04: Train Epoch 7: 40/159 Loss: 19.708382
2022-07-12 12:06: Train Epoch 7: 60/159 Loss: 24.308285
2022-07-12 12:08: Train Epoch 7: 80/159 Loss: 23.477217
2022-07-12 12:09: Train Epoch 7: 100/159 Loss: 21.041510
2022-07-12 12:11: Train Epoch 7: 120/159 Loss: 23.763323
2022-07-12 12:12: Train Epoch 7: 140/159 Loss: 22.631531
2022-07-12 12:14: **********Train Epoch 7: averaged Loss: 21.831209
2022-07-12 12:15: **********Val Epoch 7: average Loss: 22.430205
2022-07-12 12:15: *********************************Current best model saved!
2022-07-12 12:15: Train Epoch 8: 0/159 Loss: 21.792212
2022-07-12 12:17: Train Epoch 8: 20/159 Loss: 21.256020
2022-07-12 12:18: Train Epoch 8: 40/159 Loss: 22.893293
2022-07-12 12:20: Train Epoch 8: 60/159 Loss: 20.523621
2022-07-12 12:21: Train Epoch 8: 80/159 Loss: 20.987324
2022-07-12 12:23: Train Epoch 8: 100/159 Loss: 21.752804
2022-07-12 12:24: Train Epoch 8: 120/159 Loss: 19.398636
2022-07-12 12:26: Train Epoch 8: 140/159 Loss: 20.910812
2022-07-12 12:27: **********Train Epoch 8: averaged Loss: 21.034390
2022-07-12 12:29: **********Val Epoch 8: average Loss: 22.796781
2022-07-12 12:29: Train Epoch 9: 0/159 Loss: 22.790018
2022-07-12 12:30: Train Epoch 9: 20/159 Loss: 20.274687
2022-07-12 12:32: Train Epoch 9: 40/159 Loss: 21.342146
2022-07-12 12:34: Train Epoch 9: 60/159 Loss: 19.915651
2022-07-12 12:35: Train Epoch 9: 80/159 Loss: 20.407995
2022-07-12 12:37: Train Epoch 9: 100/159 Loss: 20.028725
2022-07-12 12:38: Train Epoch 9: 120/159 Loss: 19.468801
2022-07-12 12:40: Train Epoch 9: 140/159 Loss: 20.677517
2022-07-12 12:41: **********Train Epoch 9: averaged Loss: 21.027981
2022-07-12 12:43: **********Val Epoch 9: average Loss: 21.466796
2022-07-12 12:43: *********************************Current best model saved!
2022-07-12 12:43: Train Epoch 10: 0/159 Loss: 19.981688
2022-07-12 12:44: Train Epoch 10: 20/159 Loss: 19.740215
2022-07-12 12:46: Train Epoch 10: 40/159 Loss: 22.982473
2022-07-12 12:47: Train Epoch 10: 60/159 Loss: 21.278236
2022-07-12 12:49: Train Epoch 10: 80/159 Loss: 20.492243
2022-07-12 12:50: Train Epoch 10: 100/159 Loss: 20.673656
2022-07-12 12:52: Train Epoch 10: 120/159 Loss: 20.490110
2022-07-12 12:54: Train Epoch 10: 140/159 Loss: 22.199627
2022-07-12 12:55: **********Train Epoch 10: averaged Loss: 20.508356
2022-07-12 12:56: **********Val Epoch 10: average Loss: 21.688563
2022-07-12 12:56: Train Epoch 11: 0/159 Loss: 20.190033
2022-07-12 12:58: Train Epoch 11: 20/159 Loss: 21.632063
2022-07-12 12:59: Train Epoch 11: 40/159 Loss: 19.402140
2022-07-12 13:01: Train Epoch 11: 60/159 Loss: 20.910034
2022-07-12 13:03: Train Epoch 11: 80/159 Loss: 20.050169
2022-07-12 13:04: Train Epoch 11: 100/159 Loss: 32.157104
2022-07-12 13:06: Train Epoch 11: 120/159 Loss: 26.928631
2022-07-12 13:07: Train Epoch 11: 140/159 Loss: 21.229115
2022-07-12 13:09: **********Train Epoch 11: averaged Loss: 23.647346
2022-07-12 13:10: **********Val Epoch 11: average Loss: 22.819549
2022-07-12 13:10: Train Epoch 12: 0/159 Loss: 22.412128
2022-07-12 13:12: Train Epoch 12: 20/159 Loss: 22.791704
2022-07-12 13:13: Train Epoch 12: 40/159 Loss: 21.178331
2022-07-12 13:15: Train Epoch 12: 60/159 Loss: 20.826693
2022-07-12 13:16: Train Epoch 12: 80/159 Loss: 20.285337
2022-07-12 13:18: Train Epoch 12: 100/159 Loss: 20.236704
2022-07-12 13:20: Train Epoch 12: 120/159 Loss: 19.928209
2022-07-12 13:21: Train Epoch 12: 140/159 Loss: 20.209297
2022-07-12 13:23: **********Train Epoch 12: averaged Loss: 21.125487
2022-07-12 13:24: **********Val Epoch 12: average Loss: 21.420277
2022-07-12 13:24: *********************************Current best model saved!
2022-07-12 13:24: Train Epoch 13: 0/159 Loss: 22.151157
2022-07-12 13:26: Train Epoch 13: 20/159 Loss: 18.090490
2022-07-12 13:27: Train Epoch 13: 40/159 Loss: 20.459946
2022-07-12 13:29: Train Epoch 13: 60/159 Loss: 33.793697
2022-07-12 13:30: Train Epoch 13: 80/159 Loss: 27.212427
2022-07-12 13:32: Train Epoch 13: 100/159 Loss: 22.192743
2022-07-12 13:33: Train Epoch 13: 120/159 Loss: 23.942942
2022-07-12 13:35: Train Epoch 13: 140/159 Loss: 24.090105
2022-07-12 13:36: **********Train Epoch 13: averaged Loss: 24.001324
2022-07-12 13:38: **********Val Epoch 13: average Loss: 22.841832
2022-07-12 13:38: Train Epoch 14: 0/159 Loss: 19.562822
2022-07-12 13:39: Train Epoch 14: 20/159 Loss: 21.119398
2022-07-12 13:41: Train Epoch 14: 40/159 Loss: 22.057524
2022-07-12 13:42: Train Epoch 14: 60/159 Loss: 21.356983
2022-07-12 13:44: Train Epoch 14: 80/159 Loss: 22.768188
2022-07-12 13:45: Train Epoch 14: 100/159 Loss: 51.324539
2022-07-12 13:47: Train Epoch 14: 120/159 Loss: 48.955349
2022-07-12 13:49: Train Epoch 14: 140/159 Loss: 34.323093
2022-07-12 13:50: **********Train Epoch 14: averaged Loss: 30.459563
2022-07-12 13:51: **********Val Epoch 14: average Loss: 31.453752
2022-07-12 13:51: Train Epoch 15: 0/159 Loss: 28.998203
2022-07-12 13:53: Train Epoch 15: 20/159 Loss: 36.497517
2022-07-12 13:55: Train Epoch 15: 40/159 Loss: 29.203529
2022-07-12 13:56: Train Epoch 15: 60/159 Loss: 31.999613
2022-07-12 13:58: Train Epoch 15: 80/159 Loss: 30.269533
2022-07-12 13:59: Train Epoch 15: 100/159 Loss: 30.685301
2022-07-12 14:01: Train Epoch 15: 120/159 Loss: 26.853559
2022-07-12 14:02: Train Epoch 15: 140/159 Loss: 30.011805
2022-07-12 14:04: **********Train Epoch 15: averaged Loss: 30.076300
2022-07-12 14:05: **********Val Epoch 15: average Loss: 31.933775
2022-07-12 14:05: Train Epoch 16: 0/159 Loss: 29.278591
2022-07-12 14:07: Train Epoch 16: 20/159 Loss: 28.026382
2022-07-12 14:08: Train Epoch 16: 40/159 Loss: 26.515223
2022-07-12 14:10: Train Epoch 16: 60/159 Loss: 72.333809
2022-07-12 14:11: Train Epoch 16: 80/159 Loss: 53.698215
2022-07-12 14:13: Train Epoch 16: 100/159 Loss: 39.668777
2022-07-12 14:14: Train Epoch 16: 120/159 Loss: 32.210922
2022-07-12 14:16: Train Epoch 16: 140/159 Loss: 33.879002
2022-07-12 14:17: **********Train Epoch 16: averaged Loss: 38.794764
2022-07-12 14:19: **********Val Epoch 16: average Loss: 29.468340
2022-07-12 14:19: Train Epoch 17: 0/159 Loss: 29.162344
2022-07-12 14:20: Train Epoch 17: 20/159 Loss: 26.578800
2022-07-12 14:22: Train Epoch 17: 40/159 Loss: 26.115370
2022-07-12 14:23: Train Epoch 17: 60/159 Loss: 24.138571
2022-07-12 14:25: Train Epoch 17: 80/159 Loss: 28.283321
2022-07-12 14:26: Train Epoch 17: 100/159 Loss: 23.935791
2022-07-12 14:28: Train Epoch 17: 120/159 Loss: 27.392267
2022-07-12 14:30: Train Epoch 17: 140/159 Loss: 23.827984
2022-07-12 14:31: **********Train Epoch 17: averaged Loss: 25.725156
2022-07-12 14:32: **********Val Epoch 17: average Loss: 28.138056
2022-07-12 14:32: Train Epoch 18: 0/159 Loss: 26.474937
2022-07-12 14:34: Train Epoch 18: 20/159 Loss: 23.271427
2022-07-12 14:35: Train Epoch 18: 40/159 Loss: 21.930624
2022-07-12 14:37: Train Epoch 18: 60/159 Loss: 26.215549
2022-07-12 14:38: Train Epoch 18: 80/159 Loss: 22.200884
2022-07-12 14:40: Train Epoch 18: 100/159 Loss: 25.057182
2022-07-12 14:42: Train Epoch 18: 120/159 Loss: 23.692274
2022-07-12 14:43: Train Epoch 18: 140/159 Loss: 22.138437
2022-07-12 14:45: **********Train Epoch 18: averaged Loss: 23.880305
2022-07-12 14:46: **********Val Epoch 18: average Loss: 23.596382
2022-07-12 14:46: Train Epoch 19: 0/159 Loss: 23.584648
2022-07-12 14:48: Train Epoch 19: 20/159 Loss: 21.736921
2022-07-12 14:49: Train Epoch 19: 40/159 Loss: 24.167427
2022-07-12 14:51: Train Epoch 19: 60/159 Loss: 22.733086
2022-07-12 14:52: Train Epoch 19: 80/159 Loss: 22.830452
2022-07-12 14:54: Train Epoch 19: 100/159 Loss: 23.112616
2022-07-12 14:55: Train Epoch 19: 120/159 Loss: 23.976803
2022-07-12 14:57: Train Epoch 19: 140/159 Loss: 23.148468
2022-07-12 14:58: **********Train Epoch 19: averaged Loss: 22.909836
2022-07-12 15:00: **********Val Epoch 19: average Loss: 23.371048
2022-07-12 15:00: Train Epoch 20: 0/159 Loss: 21.871012
2022-07-12 15:01: Train Epoch 20: 20/159 Loss: 21.704874
2022-07-12 15:03: Train Epoch 20: 40/159 Loss: 21.128185
2022-07-12 15:04: Train Epoch 20: 60/159 Loss: 22.778875
2022-07-12 15:06: Train Epoch 20: 80/159 Loss: 22.568396
2022-07-12 15:07: Train Epoch 20: 100/159 Loss: 22.848183
2022-07-12 15:09: Train Epoch 20: 120/159 Loss: 20.254313
2022-07-12 15:10: Train Epoch 20: 140/159 Loss: 23.397602
2022-07-12 15:12: **********Train Epoch 20: averaged Loss: 22.496901
2022-07-12 15:13: **********Val Epoch 20: average Loss: 24.157499
2022-07-12 15:13: Train Epoch 21: 0/159 Loss: 23.225859
2022-07-12 15:15: Train Epoch 21: 20/159 Loss: 21.407938
2022-07-12 15:16: Train Epoch 21: 40/159 Loss: 23.925285
2022-07-12 15:18: Train Epoch 21: 60/159 Loss: 25.191000
2022-07-12 15:20: Train Epoch 21: 80/159 Loss: 23.019361
2022-07-12 15:21: Train Epoch 21: 100/159 Loss: 21.510439
2022-07-12 15:23: Train Epoch 21: 120/159 Loss: 23.805265
2022-07-12 15:24: Train Epoch 21: 140/159 Loss: 19.926962
2022-07-12 15:26: **********Train Epoch 21: averaged Loss: 22.186729
2022-07-12 15:27: **********Val Epoch 21: average Loss: 23.316129
2022-07-12 15:27: Train Epoch 22: 0/159 Loss: 21.278482
2022-07-12 15:29: Train Epoch 22: 20/159 Loss: 21.601465
2022-07-12 15:31: Train Epoch 22: 40/159 Loss: 21.880428
2022-07-12 15:32: Train Epoch 22: 60/159 Loss: 20.650579
2022-07-12 15:34: Train Epoch 22: 80/159 Loss: 20.255669
2022-07-12 15:35: Train Epoch 22: 100/159 Loss: 19.476608
2022-07-12 15:37: Train Epoch 22: 120/159 Loss: 21.348093
2022-07-12 15:39: Train Epoch 22: 140/159 Loss: 22.277254
2022-07-12 15:40: **********Train Epoch 22: averaged Loss: 22.088986
2022-07-12 15:41: **********Val Epoch 22: average Loss: 22.371025
2022-07-12 15:41: Train Epoch 23: 0/159 Loss: 21.185371
2022-07-12 15:43: Train Epoch 23: 20/159 Loss: 21.133463
2022-07-12 15:45: Train Epoch 23: 40/159 Loss: 21.581697
2022-07-12 15:46: Train Epoch 23: 60/159 Loss: 20.147699
2022-07-12 15:48: Train Epoch 23: 80/159 Loss: 21.033882
2022-07-12 15:49: Train Epoch 23: 100/159 Loss: 20.951382
2022-07-12 15:51: Train Epoch 23: 120/159 Loss: 23.210184
2022-07-12 15:53: Train Epoch 23: 140/159 Loss: 19.393866
2022-07-12 15:54: **********Train Epoch 23: averaged Loss: 21.321984
2022-07-12 15:55: **********Val Epoch 23: average Loss: 21.928028
2022-07-12 15:55: Train Epoch 24: 0/159 Loss: 20.003967
2022-07-12 15:57: Train Epoch 24: 20/159 Loss: 19.226046
2022-07-12 15:59: Train Epoch 24: 40/159 Loss: 21.189041
2022-07-12 16:00: Train Epoch 24: 60/159 Loss: 20.740620
2022-07-12 16:02: Train Epoch 24: 80/159 Loss: 19.989262
2022-07-12 16:03: Train Epoch 24: 100/159 Loss: 21.941607
2022-07-12 16:05: Train Epoch 24: 120/159 Loss: 21.516335
2022-07-12 16:06: Train Epoch 24: 140/159 Loss: 20.631008
2022-07-12 16:08: **********Train Epoch 24: averaged Loss: 21.228851
2022-07-12 16:09: **********Val Epoch 24: average Loss: 22.179022
2022-07-12 16:09: Train Epoch 25: 0/159 Loss: 19.977972
2022-07-12 16:10: Train Epoch 25: 20/159 Loss: 21.720020
2022-07-12 16:12: Train Epoch 25: 40/159 Loss: 21.266333
2022-07-12 16:13: Train Epoch 25: 60/159 Loss: 23.481121
2022-07-12 16:15: Train Epoch 25: 80/159 Loss: 21.084194
2022-07-12 16:16: Train Epoch 25: 100/159 Loss: 20.264885
2022-07-12 16:18: Train Epoch 25: 120/159 Loss: 21.116467
2022-07-12 16:19: Train Epoch 25: 140/159 Loss: 21.934820
2022-07-12 16:21: **********Train Epoch 25: averaged Loss: 21.058928
2022-07-12 16:22: **********Val Epoch 25: average Loss: 21.855630
2022-07-12 16:22: Train Epoch 26: 0/159 Loss: 22.322994
2022-07-12 16:23: Train Epoch 26: 20/159 Loss: 22.399481
2022-07-12 16:25: Train Epoch 26: 40/159 Loss: 20.859995
2022-07-12 16:27: Train Epoch 26: 60/159 Loss: 20.424480
2022-07-12 16:28: Train Epoch 26: 80/159 Loss: 19.797108
2022-07-12 16:30: Train Epoch 26: 100/159 Loss: 18.609779
2022-07-12 16:31: Train Epoch 26: 120/159 Loss: 19.219154
2022-07-12 16:32: Train Epoch 26: 140/159 Loss: 21.585613
2022-07-12 16:34: **********Train Epoch 26: averaged Loss: 20.839168
2022-07-12 16:35: **********Val Epoch 26: average Loss: 21.447709
2022-07-12 16:35: Train Epoch 27: 0/159 Loss: 19.182621
2022-07-12 16:36: Train Epoch 27: 20/159 Loss: 20.211697
2022-07-12 16:38: Train Epoch 27: 40/159 Loss: 21.262812
2022-07-12 16:39: Train Epoch 27: 60/159 Loss: 21.485126
2022-07-12 16:41: Train Epoch 27: 80/159 Loss: 22.045238
2022-07-12 16:42: Train Epoch 27: 100/159 Loss: 21.554110
2022-07-12 16:44: Train Epoch 27: 120/159 Loss: 20.145657
2022-07-12 16:45: Train Epoch 27: 140/159 Loss: 20.124651
2022-07-12 16:47: **********Train Epoch 27: averaged Loss: 20.646590
2022-07-12 16:48: **********Val Epoch 27: average Loss: 21.288600
2022-07-12 16:48: *********************************Current best model saved!
2022-07-12 16:48: Train Epoch 28: 0/159 Loss: 20.201992
2022-07-12 16:49: Train Epoch 28: 20/159 Loss: 22.818733
2022-07-12 16:51: Train Epoch 28: 40/159 Loss: 19.409233
2022-07-12 16:52: Train Epoch 28: 60/159 Loss: 21.562447
2022-07-12 16:54: Train Epoch 28: 80/159 Loss: 20.842058
2022-07-12 16:55: Train Epoch 28: 100/159 Loss: 21.819330
2022-07-12 16:57: Train Epoch 28: 120/159 Loss: 18.897560
2022-07-12 16:58: Train Epoch 28: 140/159 Loss: 19.419121
2022-07-12 16:59: **********Train Epoch 28: averaged Loss: 20.676158
2022-07-12 17:01: **********Val Epoch 28: average Loss: 22.224832
2022-07-12 17:01: Train Epoch 29: 0/159 Loss: 21.519156
2022-07-12 17:02: Train Epoch 29: 20/159 Loss: 22.645075
2022-07-12 17:03: Train Epoch 29: 40/159 Loss: 25.021351
2022-07-12 17:05: Train Epoch 29: 60/159 Loss: 20.456923
2022-07-12 17:06: Train Epoch 29: 80/159 Loss: 21.701134
2022-07-12 17:08: Train Epoch 29: 100/159 Loss: 22.791641
2022-07-12 17:09: Train Epoch 29: 120/159 Loss: 18.959944
2022-07-12 17:11: Train Epoch 29: 140/159 Loss: 20.955965
2022-07-12 17:12: **********Train Epoch 29: averaged Loss: 21.745999
2022-07-12 17:13: **********Val Epoch 29: average Loss: 22.832978
2022-07-12 17:13: Train Epoch 30: 0/159 Loss: 22.520927
2022-07-12 17:15: Train Epoch 30: 20/159 Loss: 23.853863
2022-07-12 17:16: Train Epoch 30: 40/159 Loss: 21.444525
2022-07-12 17:18: Train Epoch 30: 60/159 Loss: 20.472845
2022-07-12 17:19: Train Epoch 30: 80/159 Loss: 21.652132
2022-07-12 17:21: Train Epoch 30: 100/159 Loss: 18.499884
2022-07-12 17:22: Train Epoch 30: 120/159 Loss: 20.314165
2022-07-12 17:24: Train Epoch 30: 140/159 Loss: 21.316568
2022-07-12 17:25: **********Train Epoch 30: averaged Loss: 20.995449
2022-07-12 17:26: **********Val Epoch 30: average Loss: 21.616417
2022-07-12 17:26: Train Epoch 31: 0/159 Loss: 18.800791
2022-07-12 17:28: Train Epoch 31: 20/159 Loss: 19.796211
2022-07-12 17:29: Train Epoch 31: 40/159 Loss: 19.819565
2022-07-12 17:31: Train Epoch 31: 60/159 Loss: 20.094200
2022-07-12 17:32: Train Epoch 31: 80/159 Loss: 19.727648
2022-07-12 17:34: Train Epoch 31: 100/159 Loss: 20.456137
2022-07-12 17:35: Train Epoch 31: 120/159 Loss: 20.540356
2022-07-12 17:37: Train Epoch 31: 140/159 Loss: 20.693752
2022-07-12 17:38: **********Train Epoch 31: averaged Loss: 20.749715
2022-07-12 17:39: **********Val Epoch 31: average Loss: 20.942141
2022-07-12 17:39: *********************************Current best model saved!
2022-07-12 17:39: Train Epoch 32: 0/159 Loss: 20.871744
2022-07-12 17:41: Train Epoch 32: 20/159 Loss: 19.293640
2022-07-12 17:42: Train Epoch 32: 40/159 Loss: 20.444572
2022-07-12 17:44: Train Epoch 32: 60/159 Loss: 20.498775
2022-07-12 17:45: Train Epoch 32: 80/159 Loss: 20.169184
2022-07-12 17:47: Train Epoch 32: 100/159 Loss: 19.540770
2022-07-12 17:48: Train Epoch 32: 120/159 Loss: 21.460173
2022-07-12 17:50: Train Epoch 32: 140/159 Loss: 20.060745
2022-07-12 17:51: **********Train Epoch 32: averaged Loss: 20.237672
2022-07-12 17:52: **********Val Epoch 32: average Loss: 20.826019
2022-07-12 17:52: *********************************Current best model saved!
2022-07-12 17:52: Train Epoch 33: 0/159 Loss: 18.234718
2022-07-12 17:54: Train Epoch 33: 20/159 Loss: 19.717455
2022-07-12 17:55: Train Epoch 33: 40/159 Loss: 19.777634
2022-07-12 17:57: Train Epoch 33: 60/159 Loss: 19.486450
2022-07-12 17:58: Train Epoch 33: 80/159 Loss: 21.089132
2022-07-12 18:00: Train Epoch 33: 100/159 Loss: 26.056475
2022-07-12 18:01: Train Epoch 33: 120/159 Loss: 20.090315
2022-07-12 18:02: Train Epoch 33: 140/159 Loss: 18.185335
2022-07-12 18:04: **********Train Epoch 33: averaged Loss: 20.211612
2022-07-12 18:05: **********Val Epoch 33: average Loss: 20.947357
2022-07-12 18:05: Train Epoch 34: 0/159 Loss: 18.885605
2022-07-12 18:06: Train Epoch 34: 20/159 Loss: 21.955643
2022-07-12 18:08: Train Epoch 34: 40/159 Loss: 16.722038
2022-07-12 18:09: Train Epoch 34: 60/159 Loss: 21.593718
2022-07-12 18:11: Train Epoch 34: 80/159 Loss: 19.885416
2022-07-12 18:12: Train Epoch 34: 100/159 Loss: 21.010298
2022-07-12 18:14: Train Epoch 34: 120/159 Loss: 21.334356
2022-07-12 18:15: Train Epoch 34: 140/159 Loss: 19.339876
2022-07-12 18:16: **********Train Epoch 34: averaged Loss: 19.975238
2022-07-12 18:17: **********Val Epoch 34: average Loss: 20.641636
2022-07-12 18:17: *********************************Current best model saved!
2022-07-12 18:18: Train Epoch 35: 0/159 Loss: 19.260668
2022-07-12 18:19: Train Epoch 35: 20/159 Loss: 19.572880
2022-07-12 18:20: Train Epoch 35: 40/159 Loss: 20.899355
2022-07-12 18:22: Train Epoch 35: 60/159 Loss: 19.467525
2022-07-12 18:23: Train Epoch 35: 80/159 Loss: 20.455833
2022-07-12 18:25: Train Epoch 35: 100/159 Loss: 21.465969
2022-07-12 18:26: Train Epoch 35: 120/159 Loss: 20.159029
2022-07-12 18:28: Train Epoch 35: 140/159 Loss: 19.392551
2022-07-12 18:29: **********Train Epoch 35: averaged Loss: 19.613888
2022-07-12 18:30: **********Val Epoch 35: average Loss: 20.367932
2022-07-12 18:30: *********************************Current best model saved!
2022-07-12 18:30: Train Epoch 36: 0/159 Loss: 18.886827
2022-07-12 18:31: Train Epoch 36: 20/159 Loss: 20.457178
2022-07-12 18:33: Train Epoch 36: 40/159 Loss: 19.087927
2022-07-12 18:34: Train Epoch 36: 60/159 Loss: 19.811258
2022-07-12 18:36: Train Epoch 36: 80/159 Loss: 18.638735
2022-07-12 18:37: Train Epoch 36: 100/159 Loss: 18.706570
2022-07-12 18:39: Train Epoch 36: 120/159 Loss: 18.468548
2022-07-12 18:40: Train Epoch 36: 140/159 Loss: 19.476877
2022-07-12 18:41: **********Train Epoch 36: averaged Loss: 19.686894
2022-07-12 18:42: **********Val Epoch 36: average Loss: 20.529296
2022-07-12 18:42: Train Epoch 37: 0/159 Loss: 19.355028
2022-07-12 18:44: Train Epoch 37: 20/159 Loss: 17.802233
2022-07-12 18:45: Train Epoch 37: 40/159 Loss: 19.858807
2022-07-12 18:47: Train Epoch 37: 60/159 Loss: 18.777929
2022-07-12 18:48: Train Epoch 37: 80/159 Loss: 19.202175
2022-07-12 18:50: Train Epoch 37: 100/159 Loss: 19.911009
2022-07-12 18:51: Train Epoch 37: 120/159 Loss: 19.976385
2022-07-12 18:52: Train Epoch 37: 140/159 Loss: 20.457424
2022-07-12 18:54: **********Train Epoch 37: averaged Loss: 19.599955
2022-07-12 18:55: **********Val Epoch 37: average Loss: 20.283134
2022-07-12 18:55: *********************************Current best model saved!
2022-07-12 18:55: Train Epoch 38: 0/159 Loss: 18.643394
2022-07-12 18:56: Train Epoch 38: 20/159 Loss: 18.785509
2022-07-12 18:58: Train Epoch 38: 40/159 Loss: 18.380112
2022-07-12 18:59: Train Epoch 38: 60/159 Loss: 19.731190
2022-07-12 19:01: Train Epoch 38: 80/159 Loss: 17.930235
2022-07-12 19:02: Train Epoch 38: 100/159 Loss: 19.416332
2022-07-12 19:03: Train Epoch 38: 120/159 Loss: 18.584637
2022-07-12 19:05: Train Epoch 38: 140/159 Loss: 18.572756
2022-07-12 19:06: **********Train Epoch 38: averaged Loss: 19.401604
2022-07-12 19:07: **********Val Epoch 38: average Loss: 20.161029
2022-07-12 19:07: *********************************Current best model saved!
2022-07-12 19:07: Train Epoch 39: 0/159 Loss: 18.159161
2022-07-12 19:09: Train Epoch 39: 20/159 Loss: 18.927069
2022-07-12 19:10: Train Epoch 39: 40/159 Loss: 19.751947
2022-07-12 19:11: Train Epoch 39: 60/159 Loss: 21.126022
2022-07-12 19:13: Train Epoch 39: 80/159 Loss: 18.462528
2022-07-12 19:14: Train Epoch 39: 100/159 Loss: 20.202774
2022-07-12 19:16: Train Epoch 39: 120/159 Loss: 19.987293
2022-07-12 19:17: Train Epoch 39: 140/159 Loss: 18.964901
2022-07-12 19:18: **********Train Epoch 39: averaged Loss: 19.366284
2022-07-12 19:20: **********Val Epoch 39: average Loss: 21.010488
2022-07-12 19:20: Train Epoch 40: 0/159 Loss: 18.769880
2022-07-12 19:21: Train Epoch 40: 20/159 Loss: 19.537706
2022-07-12 19:22: Train Epoch 40: 40/159 Loss: 18.115814
2022-07-12 19:24: Train Epoch 40: 60/159 Loss: 19.119558
2022-07-12 19:25: Train Epoch 40: 80/159 Loss: 21.502289
2022-07-12 19:27: Train Epoch 40: 100/159 Loss: 19.987619
2022-07-12 19:28: Train Epoch 40: 120/159 Loss: 20.532099
2022-07-12 19:30: Train Epoch 40: 140/159 Loss: 19.540653
2022-07-12 19:31: **********Train Epoch 40: averaged Loss: 19.620496
2022-07-12 19:32: **********Val Epoch 40: average Loss: 21.066482
2022-07-12 19:32: Train Epoch 41: 0/159 Loss: 19.670605
2022-07-12 19:33: Train Epoch 41: 20/159 Loss: 19.611135
2022-07-12 19:35: Train Epoch 41: 40/159 Loss: 19.346798
2022-07-12 19:36: Train Epoch 41: 60/159 Loss: 18.757608
2022-07-12 19:38: Train Epoch 41: 80/159 Loss: 19.518023
2022-07-12 19:39: Train Epoch 41: 100/159 Loss: 19.457481
2022-07-12 19:41: Train Epoch 41: 120/159 Loss: 20.860188
2022-07-12 19:42: Train Epoch 41: 140/159 Loss: 19.047771
2022-07-12 19:43: **********Train Epoch 41: averaged Loss: 19.554036
2022-07-12 19:44: **********Val Epoch 41: average Loss: 20.230903
2022-07-12 19:44: Train Epoch 42: 0/159 Loss: 20.011757
2022-07-12 19:46: Train Epoch 42: 20/159 Loss: 19.386511
2022-07-12 19:47: Train Epoch 42: 40/159 Loss: 18.873913
2022-07-12 19:49: Train Epoch 42: 60/159 Loss: 17.784199
2022-07-12 19:50: Train Epoch 42: 80/159 Loss: 17.210033
2022-07-12 19:52: Train Epoch 42: 100/159 Loss: 20.124157
2022-07-12 19:53: Train Epoch 42: 120/159 Loss: 20.100214
2022-07-12 19:54: Train Epoch 42: 140/159 Loss: 18.687416
2022-07-12 19:56: **********Train Epoch 42: averaged Loss: 19.053714
2022-07-12 19:57: **********Val Epoch 42: average Loss: 20.043136
2022-07-12 19:57: *********************************Current best model saved!
2022-07-12 19:57: Train Epoch 43: 0/159 Loss: 19.580488
2022-07-12 19:58: Train Epoch 43: 20/159 Loss: 17.324839
2022-07-12 20:00: Train Epoch 43: 40/159 Loss: 18.745602
2022-07-12 20:01: Train Epoch 43: 60/159 Loss: 20.255863
2022-07-12 20:03: Train Epoch 43: 80/159 Loss: 18.862389
2022-07-12 20:04: Train Epoch 43: 100/159 Loss: 19.606911
2022-07-12 20:05: Train Epoch 43: 120/159 Loss: 17.274923
2022-07-12 20:07: Train Epoch 43: 140/159 Loss: 18.056015
2022-07-12 20:08: **********Train Epoch 43: averaged Loss: 19.224097
2022-07-12 20:09: **********Val Epoch 43: average Loss: 20.191403
2022-07-12 20:09: Train Epoch 44: 0/159 Loss: 18.910004
2022-07-12 20:11: Train Epoch 44: 20/159 Loss: 18.479441
2022-07-12 20:12: Train Epoch 44: 40/159 Loss: 19.782415
2022-07-12 20:14: Train Epoch 44: 60/159 Loss: 19.492218
2022-07-12 20:15: Train Epoch 44: 80/159 Loss: 20.194710
2022-07-12 20:16: Train Epoch 44: 100/159 Loss: 20.786005
2022-07-12 20:18: Train Epoch 44: 120/159 Loss: 20.488945
2022-07-12 20:19: Train Epoch 44: 140/159 Loss: 21.153126
2022-07-12 20:21: **********Train Epoch 44: averaged Loss: 19.601974
2022-07-12 20:22: **********Val Epoch 44: average Loss: 20.789711
2022-07-12 20:22: Train Epoch 45: 0/159 Loss: 20.129622
2022-07-12 20:23: Train Epoch 45: 20/159 Loss: 18.204493
2022-07-12 20:25: Train Epoch 45: 40/159 Loss: 19.673193
2022-07-12 20:26: Train Epoch 45: 60/159 Loss: 20.558392
2022-07-12 20:27: Train Epoch 45: 80/159 Loss: 21.330379
2022-07-12 20:29: Train Epoch 45: 100/159 Loss: 19.746246
2022-07-12 20:30: Train Epoch 45: 120/159 Loss: 18.447796
2022-07-12 20:32: Train Epoch 45: 140/159 Loss: 18.635324
2022-07-12 20:33: **********Train Epoch 45: averaged Loss: 19.574330
2022-07-12 20:34: **********Val Epoch 45: average Loss: 20.740373
2022-07-12 20:34: Train Epoch 46: 0/159 Loss: 19.377333
2022-07-12 20:36: Train Epoch 46: 20/159 Loss: 19.653065
2022-07-12 20:37: Train Epoch 46: 40/159 Loss: 18.792164
2022-07-12 20:38: Train Epoch 46: 60/159 Loss: 19.856907
2022-07-12 20:40: Train Epoch 46: 80/159 Loss: 17.791534
2022-07-12 20:41: Train Epoch 46: 100/159 Loss: 20.824137
2022-07-12 20:43: Train Epoch 46: 120/159 Loss: 21.761707
2022-07-12 20:44: Train Epoch 46: 140/159 Loss: 20.541357
2022-07-12 20:45: **********Train Epoch 46: averaged Loss: 20.097847
2022-07-12 20:47: **********Val Epoch 46: average Loss: 21.969172
2022-07-12 20:47: Train Epoch 47: 0/159 Loss: 19.501167
2022-07-12 20:48: Train Epoch 47: 20/159 Loss: 22.611929
2022-07-12 20:49: Train Epoch 47: 40/159 Loss: 18.350174
2022-07-12 20:51: Train Epoch 47: 60/159 Loss: 19.913151
2022-07-12 20:52: Train Epoch 47: 80/159 Loss: 18.741348
2022-07-12 20:54: Train Epoch 47: 100/159 Loss: 19.894192
2022-07-12 20:55: Train Epoch 47: 120/159 Loss: 22.190886
2022-07-12 20:57: Train Epoch 47: 140/159 Loss: 19.196243
2022-07-12 20:58: **********Train Epoch 47: averaged Loss: 20.169415
2022-07-12 20:59: **********Val Epoch 47: average Loss: 20.635052
2022-07-12 20:59: Train Epoch 48: 0/159 Loss: 19.327812
2022-07-12 21:01: Train Epoch 48: 20/159 Loss: 19.939793
2022-07-12 21:02: Train Epoch 48: 40/159 Loss: 19.293156
2022-07-12 21:03: Train Epoch 48: 60/159 Loss: 18.360752
2022-07-12 21:05: Train Epoch 48: 80/159 Loss: 18.750633
2022-07-12 21:06: Train Epoch 48: 100/159 Loss: 17.908611
2022-07-12 21:08: Train Epoch 48: 120/159 Loss: 19.006321
2022-07-12 21:09: Train Epoch 48: 140/159 Loss: 18.866383
2022-07-12 21:10: **********Train Epoch 48: averaged Loss: 18.925475
2022-07-12 21:11: **********Val Epoch 48: average Loss: 19.921388
2022-07-12 21:11: *********************************Current best model saved!
2022-07-12 21:12: Train Epoch 49: 0/159 Loss: 18.892960
2022-07-12 21:13: Train Epoch 49: 20/159 Loss: 19.062767
2022-07-12 21:14: Train Epoch 49: 40/159 Loss: 18.730190
2022-07-12 21:16: Train Epoch 49: 60/159 Loss: 19.579525
2022-07-12 21:17: Train Epoch 49: 80/159 Loss: 19.502071
2022-07-12 21:19: Train Epoch 49: 100/159 Loss: 18.003187
2022-07-12 21:20: Train Epoch 49: 120/159 Loss: 19.794930
2022-07-12 21:22: Train Epoch 49: 140/159 Loss: 20.848240
2022-07-12 21:23: **********Train Epoch 49: averaged Loss: 18.823334
2022-07-12 21:24: **********Val Epoch 49: average Loss: 19.843764
2022-07-12 21:24: *********************************Current best model saved!
2022-07-12 21:24: Train Epoch 50: 0/159 Loss: 19.189461
2022-07-12 21:25: Train Epoch 50: 20/159 Loss: 20.522686
2022-07-12 21:27: Train Epoch 50: 40/159 Loss: 18.351465
2022-07-12 21:28: Train Epoch 50: 60/159 Loss: 17.325396
2022-07-12 21:30: Train Epoch 50: 80/159 Loss: 19.342499
2022-07-12 21:31: Train Epoch 50: 100/159 Loss: 17.719688
2022-07-12 21:33: Train Epoch 50: 120/159 Loss: 19.386070
2022-07-12 21:34: Train Epoch 50: 140/159 Loss: 18.478840
2022-07-12 21:35: **********Train Epoch 50: averaged Loss: 18.734579
2022-07-12 21:36: **********Val Epoch 50: average Loss: 20.021105
2022-07-12 21:36: Train Epoch 51: 0/159 Loss: 19.301104
2022-07-12 21:38: Train Epoch 51: 20/159 Loss: 18.997070
2022-07-12 21:39: Train Epoch 51: 40/159 Loss: 20.663286
2022-07-12 21:41: Train Epoch 51: 60/159 Loss: 18.908295
2022-07-12 21:42: Train Epoch 51: 80/159 Loss: 18.328978
2022-07-12 21:44: Train Epoch 51: 100/159 Loss: 18.726088
2022-07-12 21:45: Train Epoch 51: 120/159 Loss: 18.731691
2022-07-12 21:46: Train Epoch 51: 140/159 Loss: 19.230747
2022-07-12 21:48: **********Train Epoch 51: averaged Loss: 18.981284
2022-07-12 21:49: **********Val Epoch 51: average Loss: 20.120673
2022-07-12 21:49: Train Epoch 52: 0/159 Loss: 19.115309
2022-07-12 21:50: Train Epoch 52: 20/159 Loss: 19.215387
2022-07-12 21:52: Train Epoch 52: 40/159 Loss: 19.570534
2022-07-12 21:53: Train Epoch 52: 60/159 Loss: 17.811853
2022-07-12 21:55: Train Epoch 52: 80/159 Loss: 18.480326
2022-07-12 21:56: Train Epoch 52: 100/159 Loss: 19.592102
2022-07-12 21:57: Train Epoch 52: 120/159 Loss: 18.429552
2022-07-12 21:59: Train Epoch 52: 140/159 Loss: 18.702509
2022-07-12 22:00: **********Train Epoch 52: averaged Loss: 18.759811
2022-07-12 22:01: **********Val Epoch 52: average Loss: 20.798750
2022-07-12 22:01: Train Epoch 53: 0/159 Loss: 19.425768
2022-07-12 22:03: Train Epoch 53: 20/159 Loss: 19.664268
2022-07-12 22:04: Train Epoch 53: 40/159 Loss: 19.227203
2022-07-12 22:06: Train Epoch 53: 60/159 Loss: 17.638689
2022-07-12 22:07: Train Epoch 53: 80/159 Loss: 18.432051
2022-07-12 22:08: Train Epoch 53: 100/159 Loss: 19.290581
2022-07-12 22:10: Train Epoch 53: 120/159 Loss: 19.870745
2022-07-12 22:11: Train Epoch 53: 140/159 Loss: 16.893599
2022-07-12 22:13: **********Train Epoch 53: averaged Loss: 18.972480
2022-07-12 22:14: **********Val Epoch 53: average Loss: 24.284846
2022-07-12 22:14: Train Epoch 54: 0/159 Loss: 22.828680
2022-07-12 22:15: Train Epoch 54: 20/159 Loss: 20.261639
2022-07-12 22:17: Train Epoch 54: 40/159 Loss: 19.033304
2022-07-12 22:18: Train Epoch 54: 60/159 Loss: 17.648153
2022-07-12 22:19: Train Epoch 54: 80/159 Loss: 18.035875
2022-07-12 22:21: Train Epoch 54: 100/159 Loss: 19.413300
2022-07-12 22:22: Train Epoch 54: 120/159 Loss: 19.709932
2022-07-12 22:24: Train Epoch 54: 140/159 Loss: 19.912554
2022-07-12 22:25: **********Train Epoch 54: averaged Loss: 19.927693
2022-07-12 22:26: **********Val Epoch 54: average Loss: 20.469899
2022-07-12 22:26: Train Epoch 55: 0/159 Loss: 19.408987
2022-07-12 22:28: Train Epoch 55: 20/159 Loss: 23.566576
2022-07-12 22:29: Train Epoch 55: 40/159 Loss: 20.956438
2022-07-12 22:30: Train Epoch 55: 60/159 Loss: 20.472208
2022-07-12 22:32: Train Epoch 55: 80/159 Loss: 18.238260
2022-07-12 22:33: Train Epoch 55: 100/159 Loss: 20.229244
2022-07-12 22:35: Train Epoch 55: 120/159 Loss: 19.247778
2022-07-12 22:36: Train Epoch 55: 140/159 Loss: 38.026665
2022-07-12 22:37: **********Train Epoch 55: averaged Loss: 22.522205
2022-07-12 22:39: **********Val Epoch 55: average Loss: 27.271036
2022-07-12 22:39: Train Epoch 56: 0/159 Loss: 25.803722
2022-07-12 22:40: Train Epoch 56: 20/159 Loss: 23.180176
2022-07-12 22:41: Train Epoch 56: 40/159 Loss: 20.452818
2022-07-12 22:43: Train Epoch 56: 60/159 Loss: 21.010616
2022-07-12 22:44: Train Epoch 56: 80/159 Loss: 22.555923
2022-07-12 22:46: Train Epoch 56: 100/159 Loss: 19.839920
2022-07-12 22:47: Train Epoch 56: 120/159 Loss: 20.351465
2022-07-12 22:49: Train Epoch 56: 140/159 Loss: 19.698248
2022-07-12 22:50: **********Train Epoch 56: averaged Loss: 21.330188
2022-07-12 22:51: **********Val Epoch 56: average Loss: 20.808955
2022-07-12 22:51: Train Epoch 57: 0/159 Loss: 20.220018
2022-07-12 22:52: Train Epoch 57: 20/159 Loss: 21.386482
2022-07-12 22:54: Train Epoch 57: 40/159 Loss: 19.084547
2022-07-12 22:55: Train Epoch 57: 60/159 Loss: 19.471262
2022-07-12 22:57: Train Epoch 57: 80/159 Loss: 21.065598
2022-07-12 22:58: Train Epoch 57: 100/159 Loss: 19.664145
2022-07-12 23:00: Train Epoch 57: 120/159 Loss: 20.420671
2022-07-12 23:01: Train Epoch 57: 140/159 Loss: 19.614243
2022-07-12 23:02: **********Train Epoch 57: averaged Loss: 20.009471
2022-07-12 23:03: **********Val Epoch 57: average Loss: 20.265127
2022-07-12 23:03: Train Epoch 58: 0/159 Loss: 21.167601
2022-07-12 23:05: Train Epoch 58: 20/159 Loss: 25.656349
2022-07-12 23:06: Train Epoch 58: 40/159 Loss: 25.023315
2022-07-12 23:08: Train Epoch 58: 60/159 Loss: 22.004137
2022-07-12 23:09: Train Epoch 58: 80/159 Loss: 21.604370
2022-07-12 23:11: Train Epoch 58: 100/159 Loss: 22.230877
2022-07-12 23:12: Train Epoch 58: 120/159 Loss: 21.339508
2022-07-12 23:13: Train Epoch 58: 140/159 Loss: 19.702633
2022-07-12 23:15: **********Train Epoch 58: averaged Loss: 21.920683
2022-07-12 23:16: **********Val Epoch 58: average Loss: 20.926742
2022-07-12 23:16: Train Epoch 59: 0/159 Loss: 20.170034
2022-07-12 23:17: Train Epoch 59: 20/159 Loss: 18.800896
2022-07-12 23:19: Train Epoch 59: 40/159 Loss: 20.224089
2022-07-12 23:20: Train Epoch 59: 60/159 Loss: 19.685520
2022-07-12 23:22: Train Epoch 59: 80/159 Loss: 19.269964
2022-07-12 23:23: Train Epoch 59: 100/159 Loss: 19.121853
2022-07-12 23:24: Train Epoch 59: 120/159 Loss: 21.014120
2022-07-12 23:26: Train Epoch 59: 140/159 Loss: 18.800549
2022-07-12 23:27: **********Train Epoch 59: averaged Loss: 19.842207
2022-07-12 23:28: **********Val Epoch 59: average Loss: 21.336077
2022-07-12 23:28: Train Epoch 60: 0/159 Loss: 20.449871
2022-07-12 23:30: Train Epoch 60: 20/159 Loss: 18.639011
2022-07-12 23:31: Train Epoch 60: 40/159 Loss: 18.816454
2022-07-12 23:33: Train Epoch 60: 60/159 Loss: 18.771523
2022-07-12 23:34: Train Epoch 60: 80/159 Loss: 20.345974
2022-07-12 23:35: Train Epoch 60: 100/159 Loss: 19.400921
2022-07-12 23:37: Train Epoch 60: 120/159 Loss: 19.778252
2022-07-12 23:38: Train Epoch 60: 140/159 Loss: 19.743883
2022-07-12 23:40: **********Train Epoch 60: averaged Loss: 19.463517
2022-07-12 23:41: **********Val Epoch 60: average Loss: 20.191868
2022-07-12 23:41: Train Epoch 61: 0/159 Loss: 19.230156
2022-07-12 23:42: Train Epoch 61: 20/159 Loss: 20.246510
2022-07-12 23:44: Train Epoch 61: 40/159 Loss: 19.984156
2022-07-12 23:45: Train Epoch 61: 60/159 Loss: 18.408201
2022-07-12 23:46: Train Epoch 61: 80/159 Loss: 20.847164
2022-07-12 23:48: Train Epoch 61: 100/159 Loss: 18.771049
2022-07-12 23:49: Train Epoch 61: 120/159 Loss: 20.306923
2022-07-12 23:51: Train Epoch 61: 140/159 Loss: 19.716608
2022-07-12 23:52: **********Train Epoch 61: averaged Loss: 19.291937
2022-07-12 23:53: **********Val Epoch 61: average Loss: 20.030441
2022-07-12 23:53: Train Epoch 62: 0/159 Loss: 18.417519
2022-07-12 23:55: Train Epoch 62: 20/159 Loss: 18.297955
2022-07-12 23:56: Train Epoch 62: 40/159 Loss: 19.940786
2022-07-12 23:57: Train Epoch 62: 60/159 Loss: 20.052540
2022-07-12 23:59: Train Epoch 62: 80/159 Loss: 19.107862
2022-07-13 00:00: Train Epoch 62: 100/159 Loss: 19.917353
2022-07-13 00:02: Train Epoch 62: 120/159 Loss: 20.077248
2022-07-13 00:03: Train Epoch 62: 140/159 Loss: 19.855503
2022-07-13 00:04: **********Train Epoch 62: averaged Loss: 19.415841
2022-07-13 00:05: **********Val Epoch 62: average Loss: 20.155443
2022-07-13 00:06: Train Epoch 63: 0/159 Loss: 18.849596
2022-07-13 00:07: Train Epoch 63: 20/159 Loss: 19.504311
2022-07-13 00:08: Train Epoch 63: 40/159 Loss: 25.618608
2022-07-13 00:10: Train Epoch 63: 60/159 Loss: 21.806253
2022-07-13 00:11: Train Epoch 63: 80/159 Loss: 21.689337
2022-07-13 00:13: Train Epoch 63: 100/159 Loss: 19.656391
2022-07-13 00:14: Train Epoch 63: 120/159 Loss: 19.939390
2022-07-13 00:16: Train Epoch 63: 140/159 Loss: 19.541655
2022-07-13 00:17: **********Train Epoch 63: averaged Loss: 20.856398
2022-07-13 00:18: **********Val Epoch 63: average Loss: 20.850934
2022-07-13 00:18: Train Epoch 64: 0/159 Loss: 18.689375
2022-07-13 00:19: Train Epoch 64: 20/159 Loss: 19.271225
2022-07-13 00:21: Train Epoch 64: 40/159 Loss: 19.571180
2022-07-13 00:22: Train Epoch 64: 60/159 Loss: 19.345936
2022-07-13 00:24: Train Epoch 64: 80/159 Loss: 18.131889
2022-07-13 00:25: Train Epoch 64: 100/159 Loss: 18.126286
2022-07-13 00:27: Train Epoch 64: 120/159 Loss: 19.313307
2022-07-13 00:28: Train Epoch 64: 140/159 Loss: 20.182381
2022-07-13 00:29: **********Train Epoch 64: averaged Loss: 19.169068
2022-07-13 00:30: **********Val Epoch 64: average Loss: 20.171194
2022-07-13 00:30: Validation performance didn't improve for 15 epochs. Training stops.
2022-07-13 00:30: Total training time: 831.0520min, best loss: 19.843764
2022-07-13 00:30: Saving current best model to ../runs/PEMSD4/07-12-10h39m_PEMSD4_GCDE_type1_embed{10}hid{128}hidhid{128}lyrs{3}lr{0.001}wd{0.001}/best_model.pth
target: (3394, 307, 12)
prediction: (3394, 307, 12)
MAE: 17.69
RMSE: 28.17
MAPE: 0.12
MAE: 18.47
RMSE: 29.42
MAPE: 0.13
MAE: 18.99
RMSE: 30.21
MAPE: 0.13
MAE: 19.38
RMSE: 30.74
MAPE: 0.14
MAE: 19.56
RMSE: 31.12
MAPE: 0.14
MAE: 19.77
RMSE: 31.45
MAPE: 0.14
MAE: 20.07
RMSE: 31.87
MAPE: 0.15
MAE: 20.38
RMSE: 32.38
MAPE: 0.15
MAE: 20.50
RMSE: 32.63
MAPE: 0.15
MAE: 20.71
RMSE: 33.01
MAPE: 0.15
MAE: 20.94
RMSE: 33.39
MAPE: 0.15
MAE: 21.32
RMSE: 33.90
MAPE: 0.15
all MAE: 19.81
all RMSE: 31.57
all MAPE: 0.14
[17.688559, 28.171063623576476, 0.12404497,
18.467789, 29.41722779283638, 0.12919375,
18.992273, 30.21073041854293, 0.13394627,
19.375515, 30.74305410944987, 0.13877644,
19.55603, 31.12264969006445, 0.13900468,
19.77018, 31.45154732444117, 0.14133798,
20.071886, 31.869624623343345, 0.14637919,
20.3776, 32.381665578302176, 0.14624053,
20.500443, 32.63272739844063, 0.14700525,
20.714207, 33.00605117342121, 0.14606172,
20.937296, 33.3942897643772, 0.14521722,
21.316189, 33.90195285269807, 0.14728345,

19.81401, 31.566980266792427, 0.14037453]

Process finished with exit code 0
